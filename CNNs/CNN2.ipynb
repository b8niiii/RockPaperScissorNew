{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75762930",
   "metadata": {},
   "source": [
    "From CNN1 we found that the following are the best parameters: Best config: {'out_channels': 16, 'conv_kernel_size': 7, 'pool_kernel_size': 2, 'lr': 0.0005115859153484923, 'batch_size': 16}\n",
    "\n",
    "Since we will not fine tune them this time, we will use the aforementioned ones and will focus on a more complex architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a8d7eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MediumCNN(nn.Module):\n",
    "    def __init__(self, num_classes = 3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7, padding = 7 // 2, stride =1 ), # for stride = 1, conv_kernel_size // 2 seems to be the rule of thumb\n",
    "            nn.BatchNorm2d(16), # normalizes activations inside the net, channel after channel. Makes training quicker and more efficient. Brings mean to zero and variance to 1\n",
    "            nn.ReLU(), # breaks the linearity\n",
    "            nn.MaxPool2d(2), # Pool layer that returns the highest value for each 2x2 spatial region (kernel = 2 and by default stride = kernel, so number of spatial position is 4 times smaller)\n",
    "            \n",
    "            nn.Conv2d(in_channels= 16, out_channels = 32, kernel_size = 3, padding = 1 ), \n",
    "            nn.BatchNorm2d(32), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2)\n",
    "            \n",
    "            ) \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LazyLinear(128), # lazy layer that outputs 128 units where you do not have to specify the number of in_features upfront.\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.5), \n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bac218e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0...\n",
      "Loss = 1.0325\n",
      "Validation accuracy: 0.6809815950920245\n",
      "Training epoch 1...\n",
      "Loss = 0.8012\n",
      "Validation accuracy: 0.8190184049079755\n",
      "Training epoch 2...\n",
      "Loss = 0.6631\n",
      "Validation accuracy: 0.8558282208588958\n",
      "Training epoch 3...\n",
      "Loss = 0.565\n",
      "Validation accuracy: 0.8895705521472392\n",
      "Training epoch 4...\n",
      "Loss = 0.4907\n",
      "Validation accuracy: 0.9233128834355828\n",
      "Training epoch 5...\n",
      "Loss = 0.4871\n",
      "Validation accuracy: 0.9171779141104295\n",
      "Training epoch 6...\n",
      "Loss = 0.4015\n",
      "Validation accuracy: 0.9447852760736196\n",
      "Training epoch 7...\n",
      "Loss = 0.4049\n",
      "Validation accuracy: 0.9171779141104295\n",
      "Training epoch 8...\n",
      "Loss = 0.3877\n",
      "Validation accuracy: 0.941717791411043\n",
      "Training epoch 9...\n",
      "Loss = 0.3552\n",
      "Validation accuracy: 0.9386503067484663\n",
      "Training epoch 10...\n",
      "Loss = 0.3415\n",
      "Validation accuracy: 0.941717791411043\n",
      "Training epoch 11...\n",
      "Loss = 0.3167\n",
      "Validation accuracy: 0.9478527607361963\n",
      "Training epoch 12...\n",
      "Loss = 0.295\n",
      "Validation accuracy: 0.941717791411043\n",
      "Training epoch 13...\n",
      "Loss = 0.3118\n",
      "Validation accuracy: 0.9386503067484663\n",
      "Training epoch 14...\n",
      "Loss = 0.2646\n",
      "Validation accuracy: 0.9601226993865031\n",
      "Training epoch 15...\n",
      "Loss = 0.2835\n",
      "Validation accuracy: 0.9539877300613497\n",
      "Training epoch 16...\n",
      "Loss = 0.2451\n",
      "Validation accuracy: 0.9447852760736196\n",
      "Training epoch 17...\n",
      "Loss = 0.2403\n",
      "Validation accuracy: 0.9294478527607362\n",
      "Training epoch 18...\n",
      "Loss = 0.2257\n",
      "Validation accuracy: 0.9570552147239264\n",
      "Training epoch 19...\n",
      "Loss = 0.2131\n",
      "Validation accuracy: 0.9294478527607362\n",
      "Training epoch 20...\n",
      "Loss = 0.2457\n",
      "Validation accuracy: 0.9447852760736196\n",
      "Training epoch 21...\n",
      "Loss = 0.2357\n",
      "Validation accuracy: 0.9601226993865031\n",
      "Training epoch 22...\n",
      "Loss = 0.2297\n",
      "Validation accuracy: 0.9601226993865031\n",
      "Training epoch 23...\n",
      "Loss = 0.2081\n",
      "Validation accuracy: 0.950920245398773\n",
      "Training epoch 24...\n",
      "Loss = 0.1977\n",
      "Validation accuracy: 0.9539877300613497\n",
      "Training epoch 25...\n",
      "Loss = 0.2097\n",
      "Validation accuracy: 0.9570552147239264\n",
      "Training epoch 26...\n",
      "Loss = 0.1857\n",
      "Validation accuracy: 0.9539877300613497\n",
      "Training epoch 27...\n",
      "Loss = 0.1673\n",
      "Validation accuracy: 0.9662576687116564\n",
      "Training epoch 28...\n",
      "Loss = 0.1784\n",
      "Validation accuracy: 0.9631901840490797\n",
      "Training epoch 29...\n",
      "Loss = 0.2384\n",
      "Validation accuracy: 0.9570552147239264\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim # for PyTorch optimizers\n",
    "import tempfile\n",
    "import os\n",
    "import math\n",
    "\n",
    "\n",
    "\"\"\" Create a model instance \"\"\"\n",
    "# Load datasets locally in the training function\n",
    "from torchvision import transforms, datasets # imports torchvision utilities locally inside the function - common in RayTune examples so each worker/trial can import what it needs\n",
    "\n",
    "img_size = (256, 256)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.RandomHorizontalFlip(p = 0.5),\n",
    "    transforms.RandomRotation(degrees= 15),\n",
    "    transforms.ColorJitter(\n",
    "        brightness = 0.2,\n",
    "        saturation = 0.2,\n",
    "        contrast = 0.2,\n",
    "        hue = 0.1,\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5, 0.5, 0.5],std = [0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5, 0.5, 0.5],std = [0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "\n",
    "train_ds_local = datasets.ImageFolder(\"/Users/alessandro/Progetti/RockPaperScissorNew/rps-split/train\", transform=train_transform)\n",
    "val_ds_local = datasets.ImageFolder(\"/Users/alessandro/Progetti/RockPaperScissorNew/rps-split/val\", transform=val_transform)\n",
    "\n",
    "cnn = MediumCNN()\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "cnn = cnn.to(device) # moves model parameters (weights and biases) to the target device\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr = 0.0005115859153484923, momentum = 0.9)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_ds_local,\n",
    "    batch_size = 16,\n",
    "    shuffle = True,\n",
    "    num_workers = 2,\n",
    ")\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    val_ds_local,\n",
    "    batch_size = 16,\n",
    "    shuffle = False,\n",
    "    num_workers = 2,\n",
    ")\n",
    "\n",
    "best_val_loss = math.inf\n",
    "\n",
    "for epoch in range(30):\n",
    "\n",
    "    print(f'Training epoch {epoch}...')\n",
    "    cnn.train()\n",
    "    running_loss = 0.0\n",
    "    n_train = 0\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        n_train += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / max(n_train, 1)\n",
    "\n",
    "    print(f'Loss = {round(train_loss, 4)}')\n",
    "\n",
    "    cnn.eval()\n",
    "    val_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = cnn(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * labels.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss = val_loss / max(total, 1)\n",
    "    val_acc = correct / max(total, 1)\n",
    "    print(f'Validation accuracy: {val_acc}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23cebdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(cnn.state_dict(), 'trained_cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbfc16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MediumCNN()\n",
    "net.load_state_dict(torch.load('trained_cnn.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
